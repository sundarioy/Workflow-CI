name: MLflow Project CI - Stroke Prediction (Basic)

# Trigger events
on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Manual trigger
    inputs:
      experiment_name:
        description: 'MLflow experiment name'
        required: false
        default: 'stroke_prediction_ci_manual'
      enable_tuning:
        description: 'Enable hyperparameter tuning'
        required: false
        default: 'true'
        type: choice
        options:
        - 'true'
        - 'false'

# Environment variables
env:
  PYTHON_VERSION: '3.11'
  MLFLOW_TRACKING_URI: 'file:./mlruns'

jobs:
  # Job 1: Basic validation
  validate:
    runs-on: ubuntu-latest
    name: Validate MLProject Structure
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install MLflow
      run: |
        python -m pip install --upgrade pip
        pip install mlflow>=2.0.0
        
    - name: Validate MLProject structure
      run: |
        echo "ğŸ” Validating MLProject structure..."
        ls -la MLProject/
        echo "ğŸ“‹ Checking required files:"
        test -f MLProject/MLProject && echo "âœ… MLProject file exists" || exit 1
        test -f MLProject/python_env.yaml && echo "âœ… python_env.yaml exists" || exit 1
        test -f MLProject/modelling.py && echo "âœ… modelling.py exists" || exit 1
        test -d MLProject/stroke_data_preprocessing && echo "âœ… Data directory exists" || exit 1
        echo "ğŸ¯ MLProject structure validation passed!"

  # Job 2: Quick training without tuning (for PR checks)
  train_fast:
    runs-on: ubuntu-latest
    name: Quick Model Training (No Tuning)
    needs: validate
    if: github.event_name == 'pull_request' || (github.event_name == 'workflow_dispatch' && github.event.inputs.enable_tuning == 'false')
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      run: |
        cd MLProject
        python -m pip install --upgrade pip
        pip install mlflow>=2.0.0
        pip install -r requirements.txt
        
    - name: Setup MLflow tracking
      run: |
        echo "ğŸ¯ Setting up MLflow tracking..."
        mkdir -p mlruns
        
    - name: Run fast training (no tuning)
      run: |
        echo "ğŸš€ Starting fast model training (no hyperparameter tuning)..."
        cd MLProject
        
        EXPERIMENT_NAME="stroke_prediction_fast_${GITHUB_RUN_NUMBER}"
        echo "ğŸ“Š Training with experiment: $EXPERIMENT_NAME"
        
        python modelling.py \
          --experiment-name "$EXPERIMENT_NAME" \
          --data-path "stroke_data_preprocessing" \
          --no-tuning
          
    - name: Verify training results
      run: |
        echo "ğŸ“Š Checking training results..."
        ls -la mlruns/
        echo "âœ… Fast training completed successfully!"
        
    - name: Upload training artifacts (temporary)
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-fast-training-results-${{ github.run_number }}
        path: |
          mlruns/
        retention-days: 7

  # Job 3: Full training with hyperparameter tuning (for main branch)
  train_with_tuning:
    runs-on: ubuntu-latest
    name: Full Model Training (With Tuning)
    needs: validate
    if: (github.event_name == 'push' && github.ref == 'refs/heads/main') || (github.event_name == 'workflow_dispatch' && github.event.inputs.enable_tuning == 'true')
    timeout-minutes: 60
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential
        
    - name: Install MLflow and dependencies
      run: |
        cd MLProject
        python -m pip install --upgrade pip
        pip install mlflow>=2.0.0
        pip install -r requirements.txt
        
    - name: Setup MLflow tracking
      run: |
        echo "ğŸ¯ Setting up MLflow tracking..."
        mkdir -p mlruns
        
    - name: Run full training with hyperparameter tuning
      run: |
        echo "ğŸš€ Starting full model training with hyperparameter tuning..."
        cd MLProject
        
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          EXPERIMENT_NAME="${{ github.event.inputs.experiment_name }}"
        else
          EXPERIMENT_NAME="stroke_prediction_tuned_${GITHUB_RUN_NUMBER}"
        fi
        
        echo "ğŸ“Š Training with experiment: $EXPERIMENT_NAME"
        echo "ğŸ”§ Hyperparameter tuning: ENABLED"
        
        python modelling.py \
          --experiment-name "$EXPERIMENT_NAME" \
          --data-path "stroke_data_preprocessing"
          
    - name: Extract model performance summary
      run: |
        echo "ğŸ“Š Extracting model performance summary..."
        cd MLProject
        python -c "
        import mlflow
        import pandas as pd
        import json
        
        try:
            mlflow.set_tracking_uri('file:../mlruns')
            experiments = mlflow.search_experiments()
            
            print('ğŸ“Š Training Summary:')
            for exp in experiments:
                runs = mlflow.search_runs(exp.experiment_id)
                if not runs.empty:
                    print(f'  Experiment: {exp.name}')
                    print(f'  Total runs: {len(runs)}')
                    
                    # Find best metrics
                    f1_cols = [col for col in runs.columns if 'f1_score' in col and 'metrics.' in col]
                    acc_cols = [col for col in runs.columns if 'accuracy' in col and 'metrics.' in col]
                    
                    if f1_cols:
                        best_f1 = runs[f1_cols].max().max()
                        print(f'  Best F1-Score: {best_f1:.4f}')
                    
                    if acc_cols:
                        best_acc = runs[acc_cols].max().max()
                        print(f'  Best Accuracy: {best_acc:.4f}')
                        
            print('âœ… Model training completed successfully!')
                        
        except Exception as e:
            print(f'âš ï¸ Error extracting metrics: {e}')
            print('âœ… Training completed (metrics extraction failed)')
        "
        
    - name: Verify training results
      run: |
        echo "ğŸ“Š Checking training results..."
        ls -la mlruns/
        find mlruns/ -name "*.yaml" | head -5
        echo "âœ… Full training with tuning completed successfully!"
        
    - name: Upload training artifacts (temporary)
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-tuning-results-${{ github.run_number }}
        path: |
          mlruns/
        retention-days: 30

  # Job 4: Training summary and status
  summary:
    runs-on: ubuntu-latest
    name: Training Summary
    needs: [validate, train_fast, train_with_tuning]
    if: always()
    
    steps:
    - name: Training Status Summary
      run: |
        echo "ğŸ¯ MLflow Project CI Summary"
        echo "============================"
        echo "Validation Status: ${{ needs.validate.result }}"
        echo "Fast Training Status: ${{ needs.train_fast.result }}"
        echo "Full Training Status: ${{ needs.train_with_tuning.result }}"
        echo ""
        
        # Determine overall success
        VALIDATION_OK="${{ needs.validate.result == 'success' }}"
        TRAINING_OK="${{ needs.train_fast.result == 'success' || needs.train_with_tuning.result == 'success' }}"
        
        if [ "$VALIDATION_OK" = "true" ] && [ "$TRAINING_OK" = "true" ]; then
          echo "âœ… CI Pipeline completed successfully!"
          echo ""
          if [ "${{ needs.train_with_tuning.result }}" = "success" ]; then
            echo "ğŸ‰ Full training with hyperparameter tuning completed"
            echo "ğŸ”§ Models: Logistic Regression, Random Forest, XGBoost"
            echo "ğŸ“Š All models trained with hyperparameter optimization"
          else
            echo "ğŸš€ Fast training completed (PR validation mode)"
            echo "ğŸ”§ Models: Logistic Regression, Random Forest, XGBoost"
            echo "ğŸ“Š Models trained with default parameters"
          fi
          echo ""
          echo "ğŸ“ Training artifacts available for download from GitHub Actions"
          echo "ğŸ¯ Models ready for analysis and deployment"
        else
          echo "âŒ CI Pipeline failed. Check the logs above."
          exit 1
        fi

  # Job 5: PR comment (optional - for pull requests)
  pr_comment:
    runs-on: ubuntu-latest
    name: PR Comment
    needs: [train_fast, summary]
    if: github.event_name == 'pull_request' && needs.train_fast.result == 'success'
    permissions:
      pull-requests: write
    
    steps:
    - name: Comment on PR
      uses: actions/github-script@v7
      with:
        script: |
          const runNumber = context.runNumber;
          const sha = context.sha.substring(0, 7);
          
          const comment = `## ğŸ¯ Model Training Results - Run #${runNumber}
          
          **âœ… Fast training completed successfully!**
          
          ### ğŸ“Š Training Summary
          - **Models:** Logistic Regression, Random Forest, XGBoost
          - **Mode:** Fast Training (No Hyperparameter Tuning)
          - **Commit:** \`${sha}\`
          - **Status:** All models trained and validated
          
          ### ğŸ“ Artifacts
          Training artifacts are available in the GitHub Actions run:
          - MLflow tracking data
          - Model performance metrics
          - Training logs
          
          ### ğŸš€ Next Steps
          - Merge to main branch for full training with hyperparameter tuning
          - Review model performance metrics
          - Models are ready for deployment pipeline
          
          ---
          *Automated comment from CI/CD pipeline*`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });